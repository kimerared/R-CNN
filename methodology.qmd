---
jupyter: python3
---

# Methodologies

## Fast R-CNN Training

Fast R-CNN follows a single-stage training process @girshick2015fastrcnn. It begins by processing the image through convolutional and max pooling layers, resulting in a convolutional feature map. Each object proposal then undergoes region of interest pooling, generating fixed-length feature vectors. These feature vectors are fed through fully connected layers, leading to two output layers: one for object class probabilities and the other for real-valued object coordinates. Fast R-CNN's training approach enables higher detection quality, updates all layers during training, and eliminates the need for disk storage for feature caching, contributing to its efficiency and accuracy @girshick2015fastrcnn.

## Faster R-CNN Training

On the other hand, Faster R-CNN training is a two-stage process, jointly training a Region Proposal Network (RPN) and a Fast R-CNN detector @ren2015fasterrcnn . In the first stage, the RPN generates region proposals by sliding a small network over the convolutional feature map, refining them, and assigning scores based on their likelihood of containing objects. These proposals serve as input for the second stage, where the convolutional feature map undergoes region of interest (RoI) pooling. This process results in fixed-length feature vectors for each proposal, which are then processed through fully connected layers to predict object class probabilities and refine object bounding box coordinates [@ren2015fasterrcnn, @girshick2015fastrcnn]. This joint training approach allows Faster R-CNN to produce high-quality region proposals and accurately classify and localize objects in images.

## Region Proposal Network (RPN)

To produce the object proposals used during training, a Region Proposal Network (RPN) is used. The RPN takes in an image and produces a set of object proposals with an associating score. This region proposal is generated by sliding a small network over the convolutional feature map. At the center of each sliding window is a Translation-Invariant Anchor @ren2015fasterrcnn. This anchor is a reference box that each proposal in that region is relative to. These anchors being translation-invariant means that regardless if the image is translated in any way the prediction of that region should not change.

![Figure 5: Improved anchor boxes in Faster R-CNN @zhou2022visual](images/methods/Faster-RCNN-anchor-boxes.png){style="text-align: center;" fig-alt="Improved anchor boxes in Faster R-CNN" fig-align="center"}

Three anchor boxes are depicted within each grid, as illustrated in Figure 5. The image encompasses numerous points, equivalent to a 600 x 600 image, accommodating a 38 x 38 network overlay. The blue point within the image signifies the center of the grid. Each grid center is associated with three anchor boxes and three squares of varying sizes, representing the original anchor boxes delineated in the image @zhou2022visual.

## Multi-task Loss Function

RPNs use positive and negative values to assign anchors. A positive value represents a high Intersection-over-Union overlap between the anchor and the ground truth box @ren2015fasterrcnn. A negative value represents the dissociation of an anchor and a certain prediction. The higher the value, the more associated the anchor is to a certain prediction. These values are used in a multi-task loss function. This function will both train for classification and perform bounding box regression.

$$
L = L_{cls} + λ * L_{reg}
$$

Where the RPN consist of two losses.

$$
L = (1/N) * Σ[L_{cls}(p_i, p_i*) + λ * L_{reg}(t_i, t_i*)]
$$
