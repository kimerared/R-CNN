@article{he2020maskrcnn,
  author = {K. He and G. Gkioxari and P. Doll치r and R. Girshick},
  title = {Mask R-CNN},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {42},
  number = {2},
  pages = {386-397},
  month = {Feb},
  year = {2020},
  doi = {10.1109/TPAMI.2018.2844175}
}

@inproceedings{girshick2015fastrcnn,
  author = {R. Girshick},
  title = {Fast R-CNN},
  booktitle = {2015 IEEE International Conference on Computer Vision (ICCV)},
  pages = {1440-1448},
  year = {2015},
  doi = {10.1109/ICCV.2015.169}
}

@inproceedings{ren2015fasterrcnn,
  author = {S. Ren and K. He and R. Girshick and J. Sun},
  title = {Faster R-CNN: Towards real-time object detection with region proposal networks},
  booktitle = {Advances in neural information processing systems},
  pages={91--99},
  volume = {28},
  year = {2015}
}

@article{liu2020rocktypes,
  author = {X. Liu and H. Wang and H. Jing and A. Shao and L. Wang},
  title = {Research on Intelligent Identification of Rock Types Based on Faster R-CNN Method},
  journal = {IEEE Access},
  volume = {8},
  pages = {21804-21812},
  year = {2020},
  doi = {10.1109/ACCESS.2020.2968515}
}

@inproceedings{girshick2014rich,
  author = {R. Girshick and J. Donahue and T. Darrell and J. Malik},
  title = {Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation},
  booktitle = {2014 IEEE Conference on Computer Vision and Pattern Recognition},
  pages = {580-587},
  year = {2014},
  doi = {10.1109/CVPR.2014.81}
}

@inproceedings{he2017maskrcnn,
  author = {He, Kaiming and Gkioxari, Georgia and Doll치r, Piotr and Girshick, Ross},
  title = {Mask R-CNN},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  pages = {2961-2969},
  year = {2017},
  doi = {10.1109/ICCV.2017.322}
}

@unknown{zhou2022visual,
author = {Zhou, Yibang and Wang, Xiaoyong and Zhang, Lanzhu},
year = {2022},
month = {02},
pages = {},
title = {Visual identification and pose estimation algorithm of nut tightening robot system},
doi = {10.21203/rs.3.rs-1391065/v1}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR)},
  pages={770--778},
  year={2016}
}


@article{redmon2018yolov3,
  title={Yolov3: An incremental improvement},
  author={Redmon, Joseph and Farhadi, Ali},
  journal={arXiv preprint arXiv:1804.02767},
  year={2018}
}

@inproceedings{szegedy2017inception,
  title={Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning},
  author={Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alex},
  booktitle={Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17)},
  pages={4278--4284},
  year={2017}
}

@article{uijlings2013selective,
  title={Selective Search for Object Recognition},
  author={Uijlings, J.R.R. and van de Sande, K.E.A. and Gevers, T. and Smeulders, A.W.M.},
  journal={International Journal of Computer Vision},
  volume={104},
  number={2},
  pages={154--171},
  year={2013},
}

@inproceedings{zitnick2014edge,
  title={Edge Boxes: Locating Object Proposals from Edges},
  author={Zitnick, C. Lawrence and Doll{\'a}r, Piotr},
  booktitle={European Conference on Computer Vision},
  year={2014},
  pages={391--405},
}

@software{yolov8_ultralytics,
  author = {Glenn Jocher and Ayush Chaurasia and Jing Qiu},
  title = {Ultralytics YOLOv8},
  version = {8.0.0},
  year = {2023},
  url = {https://github.com/ultralytics/ultralytics},
  orcid = {0000-0001-5950-6979, 0000-0002-7603-6750, 0000-0003-3783-7069},
  license = {AGPL-3.0}
}

@article{terven2023comprehensive,
  title={A comprehensive review of YOLO architectures in Computer Vision: From YOLOV1 to Yolov8 and Yolo-Nas},
  author={Terven, J. and C칩rdova-Esparza, D.-M. and Romero-Gonz치lez, J.-A.},
  journal={Machine Learning and Knowledge Extraction},
  volume={5},
  number={4},
  pages={1680--1716},
  year={2023},
  doi={10.3390/make5040083},
}

@article{wang2023bl,
  title={BL-Yolov8: An improved road defect detection model based on yolov8},
  author={Wang, X. and Gao, H. and Jia, Z. and Li, Z.},
  journal={Sensors},
  volume={23},
  number={20},
  pages={8361},
  year={2023},
  doi={10.3390/s23208361},
}

@inproceedings{zheng2020distance,
  title={Distance-IOU loss: Faster and better learning for bounding box regression},
  author={Zheng, Z. and Wang, P. and Liu, W. and Li, J. and Ye, R. and Ren, D.},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={07},
  pages={12993--13000},
  year={2020},
  doi={10.1609/aaai.v34i07.6999},
}

@inproceedings{li2021generalized,
  title={Generalized focal loss V2: Learning reliable localization quality estimation for dense object detection},
  author={Li, X. and Wang, W. and Hu, X. and Li, J. and Tang, J. and Yang, J.},
  booktitle={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021},
  doi={10.1109/cvpr46437.2021.01146}
}

@article{bochkovskiy2020yolov4,
  title={YOLOv4: Optimal Speed and Accuracy of Object Detection},
  author={Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan and Mishkin, Dmytro and Bu, Wenlong and Ibrahim, Mohamed and Lin, Chih-Yao},
  journal={arXiv preprint arXiv:2004.10934},
  year={2020}
}

@article{tian2019fcos,
  title={FCOS: Fully Convolutional One-Stage Object Detection},
  author={Tian, Zhi and Shen, Chunhua and Chen, Hao and He, Tong},
  journal={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9627--9636},
  year={2019}
}

@Article{ameli2024,
AUTHOR = {Ameli, Zahra and Nesheli, Shabnam Jafarpoor and Landis, Eric N.},
TITLE = {Deep Learning-Based Steel Bridge Corrosion Segmentation and Condition Rating Using Mask RCNN and YOLOv8},
JOURNAL = {Infrastructures},
VOLUME = {9},
YEAR = {2024},
NUMBER = {1},
ARTICLE-NUMBER = {3},
URL = {https://www.mdpi.com/2412-3811/9/1/3},
ISSN = {2412-3811},
ABSTRACT = {The application of deep learning (DL) algorithms has become of great interest in recent years due to their superior performance in structural damage identification, including the detection of corrosion. There has been growing interest in the application of convolutional neural networks (CNNs) for corrosion detection and classification. However, current approaches primarily involve detecting corrosion within bounding boxes, lacking the segmentation of corrosion with irregular boundary shapes. As a result, it becomes challenging to quantify corrosion areas and severity, which is crucial for engineers to rate the condition of structural elements and assess the performance of infrastructures. Furthermore, training an efficient deep learning model requires a large number of corrosion images and the manual labeling of every single image. This process can be tedious and labor-intensive. In this project, an open-source steel bridge corrosion dataset along with corresponding annotations was generated. This database contains 514 images with various corrosion severity levels, gathered from a variety of steel bridges. A pixel-level annotation was performed according to the Bridge Inspectors Reference Manual (BIRM) and the American Association of State Highway and Transportation Officials (AASHTO) regulations for corrosion condition rating (defect #1000). Two state-of-the-art semantic segmentation algorithms, Mask RCNN and YOLOv8, were trained and validated on the dataset. These trained models were then tested on a set of test images and the results were compared. The trained Mask RCNN and YOLOv8 models demonstrated satisfactory performance in segmenting and rating corrosion, making them suitable for practical applications.},
DOI = {10.3390/infrastructures9010003}
}

@article{wang2024yolov9,
  title={YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information},
  author={Wang, Chien-Yao and Yeh, I-Hau and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2402.13616v1},
  year={2024}
}

@article{fang2023improved,
  title={Improved Mask R-CNN Multi-Target Detection and Segmentation for Autonomous Driving in Complex Scenes},
  author={Fang, Shuqi and Zhang, Bin and Hu, Jingyu},
  journal={Sensors (Basel)},
  volume={23},
  number={8},
  pages={3853},
  year={2023},
  doi={10.3390/s23083853},
  PMID={37112194},
  PMCID={PMC10146362}
}

@article{erdem2020understanding,
  title={Understanding Region of Interest - Part 2 (RoI Align)},
  author={Erdem, Kemal},
  journal={Journal Name},
  year={2020}
}

@misc{wang2024yolov9,
      title={YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information}, 
      author={Chien-Yao Wang and I-Hau Yeh and Hong-Yuan Mark Liao},
      year={2024},
      eprint={2402.13616},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{wang2020cspnet,
  title={CSPNet: A New Backbone that can Enhance Learning Capability of CNN},
  author={Wang, Chien-Yao and Liao, Hong-Yuan Mark and Yeh, I-Hau and Wu, Yueh-Hua and Chen, Ping-Yang and Hsieh, Jun-Wei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  year={2020},
  pages={390--391}
}

@article{wang2023designing,
  title={Designing Network Design Strategies through Gradient Path Analysis},
  author={Wang, Chien-Yao and Liao, Hong-Yuan Mark and Yeh, I-Hau},
  journal={Journal of Information Science and Engineering (JISE)},
  volume={39},
  number={4},
  pages={975--995},
  year={2023}
}

@article{selectivesearch,
  title={Selective Search: Hierarchical Grouping for Object Detection},
  author={Author(s)},
  journal={Journal/Conference},
  year={Publication Year},
  volume={Volume},
  number={Number},
  pages={Pages},
}

@article{felzenszwalbmethod,
  title={Segmentation of Images into Regions using Felzenszwalb and Huttenlocher Method},
  author={Author(s)},
  journal={Journal/Conference},
  year={Publication Year},
  volume={Volume},
  number={Number},
  pages={Pages},
}